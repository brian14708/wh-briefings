---
date: '2023-11-01'
modified_time: 2023-11-01 12:04:46-04:00
published_time: 2023-11-01 12:04:45-04:00
source_url: https://bidenwhitehouse.archives.gov/briefing-room/speeches-remarks/2023/11/01/remarks-by-vice-president-harris-on-the-future-of-artificial-intelligence-london-united-kingdom/
tags: speeches-remarks
title: "Remarks by Vice President Harris on the Future of Artificial Intelligence\
  \ | London, United\_Kingdom"
---
 
*U.S. Embassy  
London, United Kingdom  
*

1:43 P.M. GMT  
  
THE VICE PRESIDENT:  Hello, everyone.  Good afternoon.  Good afternoon,
everyone.  (Applause.)  Please have a seat.  Good afternoon.  It’s good
to see everyone.  
  
Ambassador Hartley, thank you for the warm welcome that you gave us last
night and today, and for inviting us to be here with you.  And thank you
for your extraordinary leadership, on behalf of the President and me and
our country.  
  
And it is, of course, my honor to be with everyone here at the United
States Embassy in London, as well as to be with former Prime Minister
Theresa May and all of the leaders from the private sector, civil
society, academia, and our many international partners. 

So, tomorrow, I will participate in Prime Minister Rishi Sunak’s Global
Summit on AI Safety to continue to advance global collaboration on the
safe and responsible use of AI.  
  
Today, I will speak more broadly about the vision and the principles
that guide America’s work on AI.  
  
President Biden and I believe that all leaders from government, civil
society, and the private sector have a moral, ethical, and societal duty
to make sure that AI is adopted and advanced in a way that protects the
public from potential harm and that ensures that everyone is able to
enjoy its benefits.  
  
AI has the potential to do profound good to develop powerful new
medicines to treat and even cure the diseases that have for generations
plagued humanity, to dramatically improve agricultural production to
help address global food insecurity, and to save countless lives in the
fight against the climate crisis.  
  
But just as AI has the potential to do profound good, it also has the
potential to cause profound harm.  From AI-enabled cyberattacks at a
scale beyond anything we have seen before to AI-formulated bio-weapons
that could endanger the lives of millions, these threats are often
referred to as the “existential threats of AI” because, of course, they
could endanger the very existence of humanity. (Pause)  
  
These threats, without question, are profound, and they demand global
action.  
  
But let us be clear.  There are additional threats that also demand our
action — threats that are currently causing harm and which, to many
people, also feel existential.  
  
Consider, for example: When a senior is kicked off his healthcare plan
because of a faulty AI algorithm, is that not existential for him?  
  
When a woman is threatened by an abusive partner with explicit,
deep-fake photographs, is that not existential for her?  
  
When a young father is wrongfully imprisoned because of biased AI facial
recognition, is that not existential for his family?  
  
And when people around the world cannot discern fact from fiction
because of a flood of AI-enabled mis- and disinformation, I ask, is that
not existential for democracy?  
  
Accordingly, to define AI safety, I offer that we must consider and
address the full spectrum of AI risk — threats to humanity as a whole,
as well as threats to individuals, communities, to our institutions, and
to our most vulnerable populations.  
  
We must manage all these dangers to make sure that AI is truly safe.  
  
So, many of you here know, my mother was a scientist.  And she worked at
one of our nation’s many publicly funded research universities, which
have long served as laboratories of invention, creativity, and
progress.  
  
My mother had two goals in her life: to raise her two daughters and end
breast cancer.  At a ver- — very early age then, I learned from her
about the power of innovation to save lives, to uplift communities, and
move humanity forward.  
  
I believe history will show that this was the moment when we had the
opportunity to lay the groundwork for the future of AI.  And the urgency
of this moment must then compel us to create a collective vision of what
this future must be.  
  
A future where AI is used to advance human rights and human dignity,
where privacy is protected and people have equal access to opportunity,
where we make our democracies stronger and our world safer.  A future
where AI is used to advance the public interest.  
  
And that is the future President Joe Biden and I are building.  
  
Before generative AI captured global attention, President Biden and I
convened leaders from across our country — from computer scientists, to
civil rights activists, to business leaders, and legal scholars — all to
help make sure that the benefits of AI are shared equitably and to
address predictable threats, including deep fakes, data privacy
violations, and algorithmic discrimination.   
  
And then, we created the AI Bill of Rights.  Building on that earlier
this week, President Biden directed the United States government to
promote safe, secure, and trustworthy AI — a directive that will have
wide-ranging impact.   
  
For example, our administration will establish a national safety
reporting program on the unsafe use of AI in hospitals and medical
facilities.  Tech companies will create new tools to help consumers
discern if audio and visual content is AI-generated.  And AI developers
will be required to submit the results of AI safety testing to the
United States government for review.   
  
In addition, I am proud to announce that President Biden and I have
established the United States AI Safety Institute, which will create
rigorous standards to test the safety of AI models for public use.    
  
Today, we are also taking steps to establish requirements that when the
United States government uses AI, it advances the public interest.  And
we intend that these domestic AI policies will serve as a model for
global policy, understanding that AI developed in one nation can impact
the lives and livelihoods of billions of people around the world.   
  
Fundamentally, it is our belief that technology with global impact
deserves global action.   
  
And so, to provide order and stability in the midst of global
technological change, I firmly believe that we must be guided by a
common set of understandings among nations.  And that is why the United
States will continue to work with our allies and partners to apply
existing international rules and norms to AI and work to create new
rules and norms.   
  
To that end, earlier this year, the United States announced a set of
principles for responsible development, deployment, and use of military
AI and autonomous capabilities.  It includes a rigorous legal review
process for AI decision-making and a commitment that AI systems always
operate with international — and within international humanitarian
law.   
  
Today, I am also announcing that 30 countries have joined our commitment
to the responsible use of military AI.  And I call on more nations to
join.   
  
In addition to all of this, the United States will continue to work with
the G7; the United Nations; and a diverse range of governments, from the
Global North to the Global South, to promote AI safety and equity around
the world.   
  
But let us agree, governments alone cannot address these challenges. 
Civil society groups and the private sector also have an important role
to play. 

Civil society groups advocate for the public interest.  They hold the
public and private sectors to account and are essential to the health
and stability of our democracies. 

As with many other important issues, AI policy requires the leadership
and partnership of civil society.  And today, in response to my call, I
am proud to announce that 10 top philanthropies have committed to join
us to protect workers’ rights, advanced transparency, prevent
discrimination, drive innovation in the public interest, and help build
international rules and norms for the responsible use of AI. 

These organizations have already made an initial commitment of $200
million in furtherance of these principles. 

And so, today, I call on more civil society organizations to join us in
this effort. 

In addition to our work with civil society, President Biden and I will
continue to engage with the private companies who are building this
technology. 

Today, commercial interests are leading the way in the development and
application of large language models and making decisions about how
these models are built, trained, tested, and secured. 

These decisions have the potential to impact all of society. 

As such, President Biden and I have had extensive engagement with the
leading AI companies to establish a minimum — minimum — baseline of
responsible AI practices. 

The result is a set of voluntary company commitments, which range from
commitments to report vulnerabilities discovered in AI models to keeping
those models secure from bad actors. 

Let me be clear, these voluntary commitments are an initial step toward
a safer AI future with more to come, because, as history has shown, in
the absence of regulation and strong government oversight, some
technology companies choose to prioritize profit over the wellbeing of
their customers, the safety of our communities, and the stability of our
democracies. 

An important way to address these challenges, in addition to the work we
have already done, is through legislation — legislation that strengthens
AI safety without stifling innovation. 

In a constitutional government like the United States, the executive
branch and the legislative branch should work together to pass laws that
advance the public interest.  And we must do so swiftly, as this
technology rapidly advances. 

President Biden and I are committed to working with our partners in
Congress to codify future meaningful AI and privacy protections. 

And I will also note, even now, ahead of congressional action, there are
many existing laws and regulations that reflect our nation’s
longstanding commitment to the principles of privacy, transparency,
accountability, and consumer protection. 

These laws and regulations are enforceable and currently apply to AI
companies. 

President Biden and I reject the false choice that suggests we can
either protect the public or advance innovation.  We can and we must do
both. 

The actions we take today will lay the groundwork for how AI will be
used in the years to come.  
  
So, I will end with this: This is a moment of profound opportunity.  The
benefits of AI are immense.  It could give us the power to fight the
climate crisis, make medical and scientific breakthroughs, explore our
universe, and improve everyday life for people around the world.   
  
So, let us seize this moment.  Let us recognize this moment we are in.  
  
As leaders from government, civil society, and the private sector, let
us work together to build a future where AI creates opportunity,
advances equity, fundamental freedoms and rights being protected.  
  
Let us work together to fulfill our duty to make sure artificial
intelligence is in the service of the public interest.  
  
I thank you all.  (Applause.)  
  
                        END                1:59 P.M. GMT  
  
